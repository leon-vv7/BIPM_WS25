{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Tutorial\n",
    "\n",
    "Welcome to this interactive tutorial on **Linear Regression**! \n",
    "\n",
    "In this notebook, we will cover:\n",
    "1.  **Theory**: Understanding the math behind Linear Regression.\n",
    "2.  **Implementation**: Building a model using `scikit-learn`.\n",
    "3.  **Visualization**: Visualizing the data and the regression line.\n",
    "4.  **Exercises**: Hands-on practice to reinforce your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory\n",
    "\n",
    "### What is Linear Regression?\n",
    "Linear Regression is a supervised learning algorithm used to predict a continuous target variable ($y$) based on one or more input features ($X$). It assumes a linear relationship between the input and the output.\n",
    "\n",
    "### Simple Linear Regression\n",
    "For a single feature, the relationship is defined as:\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "$$\n",
    "Where:\n",
    "- $y$ is the dependent variable (target).\n",
    "- $x$ is the independent variable (feature).\n",
    "- $\\beta_0$ is the y-intercept.\n",
    "- $\\beta_1$ is the slope (coefficient).\n",
    "- $\\epsilon$ is the error term (noise).\n",
    "\n",
    "### Cost Function\n",
    "To find the best-fitting line, we minimize the error between the predicted values ($\\hat{y}$) and the actual values ($y$). The most common cost function is the **Mean Squared Error (MSE)**:\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "### Optimization\n",
    "Algorithms like **Gradient Descent** or the **Normal Equation** (OLS) are used to find the values of $\\beta_0$ and $\\beta_1$ that minimize the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation with scikit-learn\n",
    "\n",
    "Let's start by generating some synthetic data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Visualize the data\n",
    "plt.scatter(X, y, alpha=0.6)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Synthetic Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "It's crucial to split our data into a **training set** and a **testing set**. We train the model on the training set and evaluate its performance on the unseen testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "Now we will instantiate the `LinearRegression` model from scikit-learn and fit it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Intercept (beta_0): {model.intercept_[0]:.2f}\")\n",
    "print(f\"Coefficient (beta_1): {model.coef_[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Let's evaluate our model using the testing set. We'll look at the **Mean Squared Error (MSE)** and the **R-squared ($R^2$)** score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Regression Line\n",
    "Let's plot the regression line over our test data to see how well it fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color='black', label='Actual Data')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3, label='Regression Line')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Linear Regression Fit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercises\n",
    "\n",
    "### Exercise 1: Different Noise Levels\n",
    "Create a new synthetic dataset with a higher noise level (increase the multiplier for `np.random.randn`). \n",
    "Train a Linear Regression model on this noisy data and compare the $R^2$ score with the previous model. \n",
    "Does the model perform better or worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multiple Linear Regression\n",
    "Generate a dataset with **2 features** ($X_1, X_2$) instead of 1. \n",
    "Hint: Use `X = 2 * np.random.rand(100, 2)` and update the equation for `y` to include both features (e.g., `y = 4 + 3 * X[:, 0] + 5 * X[:, 1] + noise`).\n",
    "\n",
    "Train a model and print the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solutions\n",
    "\n",
    "<details>\n",
    "<summary>Click to see Solution for Exercise 1</summary>\n",
    "\n",
    "```python\n",
    "# High noise data\n",
    "X_noisy = 2 * np.random.rand(100, 1)\n",
    "y_noisy = 4 + 3 * X_noisy + 5 * np.random.randn(100, 1) # Increased noise multiplier to 5\n",
    "\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_noisy, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "model_noisy = LinearRegression()\n",
    "model_noisy.fit(X_train_n, y_train_n)\n",
    "\n",
    "print(f\"R^2 Score (High Noise): {model_noisy.score(X_test_n, y_test_n):.2f}\")\n",
    "# The R^2 score should be lower because the relationship is less clear due to noise.\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Click to see Solution for Exercise 2</summary>\n",
    "\n",
    "```python\n",
    "# Multiple features\n",
    "X_multi = 2 * np.random.rand(100, 2)\n",
    "y_multi = 4 + 3 * X_multi[:, 0] + 5 * X_multi[:, 1] + np.random.randn(100)\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)\n",
    "\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train_m, y_train_m)\n",
    "\n",
    "print(f\"Coefficients: {model_multi.coef_}\")\n",
    "print(f\"Intercept: {model_multi.intercept_:.2f}\")\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
