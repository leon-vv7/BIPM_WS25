{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MykWsahVTkuu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8rKvdQgTlHy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7WdgY-aTlYt"
   },
   "source": [
    "## Diamonds\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Fit a linear regression (price as outcome) including all columns !\n",
    "2. Get the R^2 on the test data and compare to training\n",
    "3. Which features seem important\n",
    "4. What about x,y,z ? Do they make sense to include in a linear fashion ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T69zbkCTmBS",
    "outputId": "07c7a428-1806-45de-92cb-ef1bbd3e6fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['cut', 'color', 'clarity']\n",
      "Numeric: ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
      "Train R²: 0.919994314909212\n",
      "Test R²: 0.9189331350419379\n",
      "          feature   coefficient\n",
      "0        cut_Good    591.797169\n",
      "1       cut_Ideal    858.815946\n",
      "2     cut_Premium    781.928178\n",
      "3   cut_Very Good    749.952180\n",
      "4         color_E   -218.198603\n",
      "5         color_F   -279.716403\n",
      "6         color_G   -495.581527\n",
      "7         color_H   -999.086408\n",
      "8         color_I  -1479.584470\n",
      "9         color_J  -2372.019835\n",
      "10     clarity_IF   5365.944596\n",
      "11    clarity_SI1   3675.414552\n",
      "12    clarity_SI2   2701.439970\n",
      "13    clarity_VS1   4579.905541\n",
      "14    clarity_VS2   4263.615635\n",
      "15   clarity_VVS1   5015.292916\n",
      "16   clarity_VVS2   4958.211449\n",
      "17          carat  11280.784327\n",
      "18          depth    -65.091015\n",
      "19          table    -26.600021\n",
      "20              x  -1008.041596\n",
      "21              y     -3.528450\n",
      "22              z    -36.463370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Load diamonds data\n",
    "# -------------------------------------------------------\n",
    "df = sm.datasets.get_rdataset(\"diamonds\", \"ggplot2\").data\n",
    "\n",
    "# Outcome:\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Predictors:\n",
    "X = df.drop(columns=[\"price\"])\n",
    "\n",
    "# Identify categorical vs numeric columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numeric:\", numeric_cols)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Preprocessor: OneHotEncoder for categoricals\n",
    "# -------------------------------------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Full pipeline\n",
    "# -------------------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Train–test split and fit\n",
    "# -------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train R²:\", pipe.score(X_train, y_train))\n",
    "print(\"Test R²:\", pipe.score(X_test, y_test))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Get coefficient names\n",
    "# -------------------------------------------------------\n",
    "# 1. Get names from the ColumnTransformer\n",
    "ohe = pipe.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "\n",
    "feature_names = list(ohe_feature_names) + numeric_cols\n",
    "\n",
    "# 2. Get coefficients from model\n",
    "coefs = pipe.named_steps[\"model\"].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": coefs\n",
    "})\n",
    "\n",
    "print(coef_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZPTCuAWWWw6",
    "outputId": "0c71e4c8-6c62-4aec-bc2a-4daedfe04180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.91797169e+02,  8.58815946e+02,  7.81928178e+02,  7.49952180e+02,\n",
       "       -2.18198603e+02, -2.79716403e+02, -4.95581527e+02, -9.99086408e+02,\n",
       "       -1.47958447e+03, -2.37201983e+03,  5.36594460e+03,  3.67541455e+03,\n",
       "        2.70143997e+03,  4.57990554e+03,  4.26361564e+03,  5.01529292e+03,\n",
       "        4.95821145e+03,  1.12807843e+04, -6.50910151e+01, -2.66000210e+01,\n",
       "       -1.00804160e+03, -3.52845036e+00, -3.64633703e+01])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps[\"model\"].coef_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAIvywpwUsYR",
    "outputId": "23dbd155-92ff-4eb1-a5fb-42e7a0df6b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALPR4BxtW4Fc",
    "outputId": "003e5b46-7b2f-4413-b1dd-7dde926f258b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.920\n",
      "Model:                            OLS   Adj. R-squared:                  0.920\n",
      "Method:                 Least Squares   F-statistic:                 2.688e+04\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:35:06   Log-Likelihood:            -4.5573e+05\n",
      "No. Observations:               53940   AIC:                         9.115e+05\n",
      "Df Residuals:                   53916   BIC:                         9.117e+05\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept         2184.4774    408.197      5.352      0.000    1384.409    2984.546\n",
      "cut[T.Good]        579.7514     33.592     17.259      0.000     513.911     645.592\n",
      "cut[T.Ideal]       832.9118     33.407     24.932      0.000     767.433     898.391\n",
      "cut[T.Premium]     762.1440     32.228     23.649      0.000     698.978     825.310\n",
      "cut[T.Very Good]   726.7826     32.241     22.542      0.000     663.591     789.975\n",
      "color[T.E]        -209.1181     17.893    -11.687      0.000    -244.189    -174.047\n",
      "color[T.F]        -272.8538     18.093    -15.081      0.000    -308.316    -237.392\n",
      "color[T.G]        -482.0389     17.716    -27.209      0.000    -516.763    -447.315\n",
      "color[T.H]        -980.2667     18.836    -52.043      0.000   -1017.185    -943.348\n",
      "color[T.I]       -1466.2445     21.162    -69.286      0.000   -1507.723   -1424.766\n",
      "color[T.J]       -2369.3981     26.131    -90.674      0.000   -2420.615   -2318.181\n",
      "clarity[T.IF]     5345.1022     51.024    104.757      0.000    5245.095    5445.110\n",
      "clarity[T.SI1]    3665.4721     43.634     84.005      0.000    3579.949    3750.995\n",
      "clarity[T.SI2]    2702.5863     43.818     61.677      0.000    2616.702    2788.471\n",
      "clarity[T.VS1]    4578.3979     44.546    102.779      0.000    4491.087    4665.708\n",
      "clarity[T.VS2]    4267.2236     43.853     97.306      0.000    4181.270    4353.177\n",
      "clarity[T.VVS1]   5007.7590     47.160    106.187      0.000    4915.326    5100.192\n",
      "clarity[T.VVS2]   4950.8141     45.855    107.967      0.000    4860.938    5040.690\n",
      "carat             1.126e+04     48.628    231.494      0.000    1.12e+04    1.14e+04\n",
      "depth              -63.8061      4.535    -14.071      0.000     -72.694     -54.918\n",
      "table              -26.4741      2.912     -9.092      0.000     -32.181     -20.767\n",
      "x                -1008.2611     32.898    -30.648      0.000   -1072.741    -943.781\n",
      "y                    9.6089     19.333      0.497      0.619     -28.284      47.502\n",
      "z                  -50.1189     33.486     -1.497      0.134    -115.752      15.515\n",
      "==============================================================================\n",
      "Omnibus:                    14433.356   Durbin-Watson:                   1.183\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           565680.446\n",
      "Skew:                           0.577   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.823   Cond. No.                     7.14e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.14e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(\"price ~ carat + depth + cut + color + clarity+ depth+ table + x + y+ z\", data=df).fit()\n",
    "\n",
    "print(model.summary())#.tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBX6x96Ialpm",
    "outputId": "14355c5b-0ed3-49ab-a8fd-5fc053e22cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  carat   R-squared:                       0.952\n",
      "Model:                            OLS   Adj. R-squared:                  0.952\n",
      "Method:                 Least Squares   F-statistic:                 3.536e+05\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:35:06   Log-Likelihood:                 45412.\n",
      "No. Observations:               53940   AIC:                        -9.082e+04\n",
      "Df Residuals:                   53936   BIC:                        -9.078e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.5668      0.002   -669.401      0.000      -1.571      -1.562\n",
      "x              0.3591      0.002    156.316      0.000       0.355       0.364\n",
      "y              0.0052      0.002      2.914      0.004       0.002       0.009\n",
      "z              0.0784      0.003     29.396      0.000       0.073       0.084\n",
      "==============================================================================\n",
      "Omnibus:                    57670.233   Durbin-Watson:                   0.784\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         25221338.363\n",
      "Skew:                           4.766   Prob(JB):                         0.00\n",
      "Kurtosis:                     108.504   Cond. No.                         65.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(\"carat ~  x + y+ z\", data=df).fit()\n",
    "\n",
    "print(model.summary())#.tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUvHXJrpUtJB"
   },
   "source": [
    "## Interactions\n",
    "\n",
    "Also known in the business context as\n",
    "**synergies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XmI3LC1Usf6",
    "outputId": "81845b42-6b57-4c08-b4a0-cd783cfe8e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.851\n",
      "Model:                            OLS   Adj. R-squared:                  0.851\n",
      "Method:                 Least Squares   F-statistic:                 1.536e+05\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:35:06   Log-Likelihood:            -4.7249e+05\n",
      "No. Observations:               53940   AIC:                         9.450e+05\n",
      "Df Residuals:                   53937   BIC:                         9.450e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   4045.3332    286.205     14.134      0.000    3484.368    4606.298\n",
      "carat       7765.1407     14.009    554.282      0.000    7737.682    7792.599\n",
      "depth       -102.1653      4.635    -22.041      0.000    -111.251     -93.080\n",
      "==============================================================================\n",
      "Omnibus:                    14148.858   Durbin-Watson:                   0.992\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           148236.675\n",
      "Skew:                           0.962   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.890   Cond. No.                     2.66e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.66e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(\"price ~ carat + depth\", data=df).fit()\n",
    "\n",
    "print(model.summary())#.tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq103LPWbqAt",
    "outputId": "d43db66a-5343-4ae5-d7be-d930a71aefa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.852\n",
      "Model:                            OLS   Adj. R-squared:                  0.852\n",
      "Method:                 Least Squares   F-statistic:                 1.036e+05\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:37:46   Log-Likelihood:            -4.7223e+05\n",
      "No. Observations:               53940   AIC:                         9.445e+05\n",
      "Df Residuals:                   53936   BIC:                         9.445e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept   -7823.7383    592.049    -13.215      0.000   -8984.158   -6663.318\n",
      "carat        2.074e+04    567.672     36.540      0.000    1.96e+04    2.19e+04\n",
      "depth          90.0432      9.588      9.391      0.000      71.251     108.836\n",
      "carat:depth  -210.0753      9.187    -22.868      0.000    -228.081    -192.070\n",
      "==============================================================================\n",
      "Omnibus:                    14524.513   Durbin-Watson:                   0.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           134929.068\n",
      "Skew:                           1.030   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.469   Cond. No.                     9.78e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.78e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(\"price ~ carat * depth\", data=df).fit()\n",
    "\n",
    "print(model.summary())#.tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvcQINwVVGwO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Load data\n",
    "\n",
    "df = sm.datasets.get_rdataset(\"diamonds\", \"ggplot2\").data\n",
    "\n",
    "df= pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vmjl0uEeVcDD"
   },
   "source": [
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTUiA3--VdHP",
    "outputId": "770635db-8543-4acb-b964-ddd905f8ddf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [20742.59987133    90.04321842  -210.07533218]\n",
      "Intercept: -7823.738251003058\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load diamonds\n",
    "#df = sm.datasets.get_rdataset(\"diamonds\", \"ggplot2\").data\n",
    "\n",
    "X = df[[\"carat\", \"depth\"]]   # same variables as in statsmodels formula\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Pipeline: interaction terms only\n",
    "pipe = Pipeline([\n",
    "    (\"interaction\", PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "print(\"Coefficients:\", pipe.named_steps[\"model\"].coef_)\n",
    "print(\"Intercept:\", pipe.named_steps[\"model\"].intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgNATcmzVjEN"
   },
   "source": [
    "show the expanded feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jig9HpwQViKg",
    "outputId": "4ae9ef72-5971-4444-ba60-b0545563390c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23  61.5   14.145]\n",
      " [ 0.21  59.8   12.558]\n",
      " [ 0.23  56.9   13.087]\n",
      " [ 0.29  62.4   18.096]\n",
      " [ 0.31  63.3   19.623]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_trans = pipe.named_steps[\"interaction\"].fit_transform(X)\n",
    "print(X_trans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
